CLIP과 같은 Multimodal Model은 이미지와 텍스트를 어떻게 처리할까?

